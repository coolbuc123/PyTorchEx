{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "induced-language",
   "metadata": {},
   "source": [
    "### Pad_Packed Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beneficial-growing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello world', 'midnight', 'calculation', 'path', 'short circuit']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Random word from random word generator\n",
    "data = ['hello world',\n",
    "        'midnight',\n",
    "        'calculation',\n",
    "        'path',\n",
    "        'short circuit']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-assault",
   "metadata": {},
   "source": [
    "### char vocab 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sound-experiment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_set: ['<pad>', 'c', 'p', ' ', 's', 'h', 'r', 'e', 'a', 'i', 'n', 'g', 't', 'o', 'u', 'l', 'm', 'd', 'w']\n"
     ]
    }
   ],
   "source": [
    "# Make dictionary\n",
    "char_set = ['<pad>'] + list(set(char for seq in data for char in seq)) # Get all characters and include pad token\n",
    "print('char_set:', char_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "gothic-oregon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, 'c': 1, 'p': 2, ' ': 3, 's': 4, 'h': 5, 'r': 6, 'e': 7, 'a': 8, 'i': 9, 'n': 10, 'g': 11, 't': 12, 'o': 13, 'u': 14, 'l': 15, 'm': 16, 'd': 17, 'w': 18}\n",
      "char_set length: 19\n"
     ]
    }
   ],
   "source": [
    "char2idx = {char: idx for idx, char in enumerate(char_set)} # Constuct character to index dictionary\n",
    "print(char2idx)\n",
    "print('char_set length:', len(char_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-sauce",
   "metadata": {},
   "source": [
    "#### 문장별로 idx화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "differential-cassette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 5,  7, 15, 15, 13,  3, 18, 13,  6, 15, 17]),\n",
       " tensor([16,  9, 17, 10,  9, 11,  5, 12]),\n",
       " tensor([ 1,  8, 15,  1, 14, 15,  8, 12,  9, 13, 10]),\n",
       " tensor([ 2,  8, 12,  5]),\n",
       " tensor([ 4,  5, 13,  6, 12,  3,  1,  9,  6,  1, 14,  9, 12])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert character to index and\n",
    "# Make list of tensors\n",
    "X = [torch.LongTensor([char2idx[char] for char in seq]) for seq in data]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-authorization",
   "metadata": {},
   "source": [
    "### Pad Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "subtle-testing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5,  7, 15, 15, 13,  3, 18, 13,  6, 15, 17,  0,  0],\n",
      "        [16,  9, 17, 10,  9, 11,  5, 12,  0,  0,  0,  0,  0],\n",
      "        [ 1,  8, 15,  1, 14, 15,  8, 12,  9, 13, 10,  0,  0],\n",
      "        [ 2,  8, 12,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 4,  5, 13,  6, 12,  3,  1,  9,  6,  1, 14,  9, 12]])\n",
      "torch.Size([5, 13])\n"
     ]
    }
   ],
   "source": [
    "# Make a Tensor of shape (Batch x Maximum_Sequence_Length)\n",
    "padded_sequence = pad_sequence(X, batch_first=True) # X is now padded sequence\n",
    "print(padded_sequence)\n",
    "print(padded_sequence.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-lingerie",
   "metadata": {},
   "source": [
    "#### 내림차순 정렬(Packed 위해서는)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "usual-edition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths: [11, 8, 11, 4, 13]\n"
     ]
    }
   ],
   "source": [
    "# Make length tensor (will be used later in 'pack_padded_sequence' function)\n",
    "raw_lengths = [len(seq) for seq in X]\n",
    "print('lengths:', raw_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "first-moderator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 0, 2, 1, 3]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 내림차순 : reverse = True\n",
    "sorted_idx = sorted(range(len(lengths)), key=raw_lengths.__getitem__, reverse=True)\n",
    "sorted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "earlier-angel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 4,  5, 13,  6, 12,  3,  1,  9,  6,  1, 14,  9, 12]),\n",
       " tensor([ 5,  7, 15, 15, 13,  3, 18, 13,  6, 15, 17]),\n",
       " tensor([ 1,  8, 15,  1, 14, 15,  8, 12,  9, 13, 10]),\n",
       " tensor([16,  9, 17, 10,  9, 11,  5, 12]),\n",
       " tensor([ 2,  8, 12,  5])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_X = [X[idx] for idx in sorted_idx]\n",
    "sorted_X "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-doctor",
   "metadata": {},
   "source": [
    "### Packed Sequence : 세로로 자른다(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "defensive-destruction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequence(data=tensor([ 4,  5,  1, 16,  2,  5,  7,  8,  9,  8, 13, 15, 15, 17, 12,  6, 15,  1,\n",
      "        10,  5, 12, 13, 14,  9,  3,  3, 15, 11,  1, 18,  8,  5,  9, 13, 12, 12,\n",
      "         6,  6,  9,  1, 15, 13, 14, 17, 10,  9, 12]), batch_sizes=tensor([5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 1, 1]), sorted_indices=None, unsorted_indices=None)\n"
     ]
    }
   ],
   "source": [
    "packed_sequence = pack_sequence(sorted_X)\n",
    "print(packed_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-involvement",
   "metadata": {},
   "source": [
    "### One-hot Embeding 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "timely-arthur",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 19])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot embedding using PaddedSequence\n",
    "eye = torch.eye(len(char_set)) # Identity matrix of shape (len(char_set), len(char_set))\n",
    "eye.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-commercial",
   "metadata": {},
   "source": [
    "#### Pad One-hot : 문장별 무조건 13개씩을 vocab[19] 기준으로 one-hot ( 5 X 13 = 65개를 One-Hot )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "circular-offense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 13, 19])\n"
     ]
    }
   ],
   "source": [
    "embedded_tensor = eye[padded_sequence]\n",
    "print(embedded_tensor.shape) # shape: (Batch_size, max_sequence_length, number_of_input_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-humanitarian",
   "metadata": {},
   "source": [
    "#### Packed One-hot : 존재하는 대상 47개만 vocab[19] 기준으로 one-hot ( Pad 대비 효율성 초점 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eleven-speaking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 19])\n"
     ]
    }
   ],
   "source": [
    "# one-hot embedding using PackedSequence\n",
    "embedded_packed_seq = pack_sequence([eye[X[idx]] for idx in sorted_idx])\n",
    "print(embedded_packed_seq.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-royal",
   "metadata": {},
   "source": [
    "##### (예) Pad 1개만 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "unable-hormone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  7, 15, 15, 13,  3, 18, 13,  6, 15, 17,  0,  0],\n",
       "        [16,  9, 17, 10,  9, 11,  5, 12,  0,  0,  0,  0,  0],\n",
       "        [ 1,  8, 15,  1, 14, 15,  8, 12,  9, 13, 10,  0,  0],\n",
       "        [ 2,  8, 12,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 4,  5, 13,  6, 12,  3,  1,  9,  6,  1, 14,  9, 12]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "substantial-chest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "supposed-guess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 13, 30])\n"
     ]
    }
   ],
   "source": [
    "# declare RNN\n",
    "rnn = torch.nn.RNN(input_size=len(char_set), hidden_size=30, batch_first=True)\n",
    "\n",
    "# Try out PaddedSequence\n",
    "rnn_output, hidden = rnn(embedded_tensor)\n",
    "print(rnn_output.shape) # shape: (batch_size, max_seq_length, hidden_size)\n",
    "# print(hidden.shape)     # shape: (num_layers * num_directions, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "toxic-corruption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 30])\n"
     ]
    }
   ],
   "source": [
    "# Try out PackedSequence\n",
    "rnn_output, hidden = rnn(embedded_packed_seq)\n",
    "print(rnn_output.data.shape)\n",
    "# print(hidden.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-toilet",
   "metadata": {},
   "source": [
    "### pad ← packed : pad_packed_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "similar-excerpt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 13, 19])\n",
      "tensor([13, 11, 11,  8,  4])\n"
     ]
    }
   ],
   "source": [
    "# Try out pad_packed_sequence\n",
    "unpacked_sequence, seq_lengths = pad_packed_sequence(embedded_packed_seq, batch_first=True)\n",
    "print(unpacked_sequence.shape)\n",
    "print(seq_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-major",
   "metadata": {},
   "source": [
    "### packed ← pad : pack_padded_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "confirmed-helena",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 13, 19])\n"
     ]
    }
   ],
   "source": [
    "# Construct embedded_padded_sequence\n",
    "embedded_padded_sequence = eye[pad_sequence(sorted_X, batch_first=True)]\n",
    "print(embedded_padded_sequence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "radical-handle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 19])\n",
      "tensor([5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Try out pack_padded_sequence\n",
    "sorted_lengths = sorted(lengths, reverse=True)\n",
    "new_packed_sequence = pack_padded_sequence(embedded_padded_sequence, sorted_lengths, batch_first=True)\n",
    "print(new_packed_sequence.data.shape)\n",
    "print(new_packed_sequence.batch_sizes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python My Env",
   "language": "python",
   "name": "python-my-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
