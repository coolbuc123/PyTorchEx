{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "thrown-police",
   "metadata": {},
   "source": [
    "### generate_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "skilled-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# this should be called in main file\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os, pathlib, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sticky-township",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/raid/workspace/public/libs/pytorch_examples'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath('/raid/workspace/public/libs/pytorch_examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "played-elder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hubuc/.local/lib/python3.6/site-packages/torch/__init__.py'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adapted-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.remove('/home/hubuc/model/time_series/~ /raid/workspace/public',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "local-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.remove('/home/hubuc/.local/lib/python3.6/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "photographic-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.remove( '/home/hubuc/.ipython',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "electric-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('home/hubuc/.local/lib/python3.6/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "reserved-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('home/hubuc/.ipython')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "natural-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path = ['',\n",
    " '/home/adminuser/.local/lib/python3.6/site-packages',\n",
    " '/opt/conda/envs/python/lib/python36.zip',\n",
    " '/opt/conda/envs/python/lib/python3.6',\n",
    " '/opt/conda/envs/python/lib/python3.6/lib-dynload',\n",
    " '/opt/conda/envs/python/lib/python3.6/site-packages',            \n",
    " '/home/hubuc/.local/lib/python3.6/site-packages',\n",
    "\n",
    " '/opt/conda/envs/python/lib/python3.6/site-packages/IPython/extensions',\n",
    " 'home/hubuc/.local/lib/python3.6/site-packages',\n",
    " 'home/hubuc/.ipython']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "friendly-corps",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-standard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "equal-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module_dir = pathlib.Path(__file__).parent.parent.absolute()\n",
    "sys.path.append(str('/raid/workspace/public/libs/pytorch_examples'))\n",
    "from kbutils.evaluation import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-passenger",
   "metadata": {},
   "source": [
    "### get_MLP 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "improved-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MLP(dim_hiddens, activation=nn.ReLU(), dropout=0.1, end=False):\n",
    "    \"\"\"\n",
    "    help to easily build an MLP model\n",
    "    >>> encoder = get_MLP([784, 128, 64, 32])\n",
    "    \n",
    "    :param dim_hiddens: list of hidden layer sizes\n",
    "    :param end: True = regression(no activation at the end), False = activation at the end\n",
    "    :return: Sequential of pytorch MLP\n",
    "    \"\"\"\n",
    "    def get_a_layer(n_in, n_out, activation, dropout, end=False):\n",
    "        seq = [nn.Dropout(dropout), nn.Linear(n_in, n_out), activation]\n",
    "        if end is True:\n",
    "            return seq[:-1]\n",
    "        else:\n",
    "            return seq\n",
    "    \n",
    "    layers = []\n",
    "    ii = 0\n",
    "    n_hidden = len(dim_hiddens)\n",
    "    for n_in, n_out in zip(dim_hiddens, dim_hiddens[1:]):\n",
    "        if ii == n_hidden-1-1: # at last layer\n",
    "            layer = get_a_layer(n_in, n_out, activation, dropout, end=end)\n",
    "        else:\n",
    "            layer = get_a_layer(n_in, n_out, activation, dropout, end=False)\n",
    "        layers.append(layer)\n",
    "        ii += 1\n",
    "        \n",
    "    layers = [ x for xs in layers for x in xs ]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-notion",
   "metadata": {},
   "source": [
    "### 기본 Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "oriental-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    This class defines network learning and test behaviors. \n",
    "    It gets model, loss and optimizer\n",
    "    \"\"\"\n",
    "    def __init__(self, model=None, loss=None, \n",
    "                 optimizer=None, device='cuda'):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def set_train(self):\n",
    "        \"\"\"\n",
    "        initialization for training\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "    \n",
    "    def set_eval(self):\n",
    "        \"\"\"\n",
    "        initialization for evaluation\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        describe weight initialization method\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        describe network forward action\n",
    "        \"\"\"\n",
    "        return self.model(x)\n",
    "    \n",
    "    def run_batch(self, i_batch, data):\n",
    "        \"\"\"\n",
    "        learning method for a batch.\n",
    "        You can override this in sub-class\n",
    "        \"\"\"\n",
    "        self.optimizer.zero_grad()\n",
    "        data_in, tgt = data\n",
    "        data_in = data_in.to(self.device)\n",
    "        tgt = tgt.to(self.device)\n",
    "        out = self.forward(data_in)\n",
    "        loss = self.loss(out, tgt)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.detach().cpu().item()\n",
    "    \n",
    "    def run_train(self, n_epoch, data, test_data=None, eval_step=1):\n",
    "        \"\"\"\n",
    "        training method definition\n",
    "        :param data: training data\n",
    "        :param test_data: validation data\n",
    "        \"\"\"\n",
    "        for i_epoch in range(n_epoch):\n",
    "            self.set_train()\n",
    "            loss = 0\n",
    "            for i_batch, data_batch in enumerate(data):\n",
    "                loss_temp = self.run_batch(i_batch, data_batch)\n",
    "                loss += loss_temp\n",
    "            loss /= 1.0*len(data)\n",
    "            print('epoch', i_epoch, 'loss', loss)\n",
    "            \n",
    "            if eval_step>0 and (i_epoch+1)%eval_step==0:\n",
    "                if test_data is None:\n",
    "                    print('eval_train', end=' ')\n",
    "                    self.run_eval(data)\n",
    "                else:\n",
    "                    self.run_eval(test_data)\n",
    "        \n",
    "    def run_eval(self, data):\n",
    "        \"\"\"\n",
    "        test method definition\n",
    "        :return: (prediction, target, loss)\n",
    "        \"\"\"\n",
    "        self.set_eval()\n",
    "        loss = 0\n",
    "        outs = None\n",
    "        tgts = None\n",
    "        with torch.no_grad():\n",
    "            for i_batch, data_batch in enumerate(data):\n",
    "                data_in, tgt = data_batch\n",
    "                data_in = data_in.to(self.device)\n",
    "                tgt = tgt.to(self.device)\n",
    "                out = self.forward(data_in)\n",
    "                loss += self.loss(out, tgt).detach().cpu()\n",
    "                softmaxout = self.softmax(out).cpu().numpy()\n",
    "                tgt = tgt.cpu().numpy()\n",
    "                if outs is None:\n",
    "                    outs = softmaxout\n",
    "                    tgts = tgt\n",
    "                else:\n",
    "                    outs = np.concatenate((outs, softmaxout), axis=0)\n",
    "                    tgts = np.concatenate((tgts, tgt), axis=0)\n",
    "        loss /= 1.0*(i_batch+1)\n",
    "        print('evaluate', 'loss', loss, 'accuracy', accuracy(outs, tgts))\n",
    "        return outs, tgts, loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-digit",
   "metadata": {},
   "source": [
    "### class Autoencoder(Net):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dedicated-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Net):\n",
    "    \"\"\"\n",
    "    class for Autoencoder\n",
    "    \n",
    "    >>> dims = [784, 128, 64, 32]\n",
    "    >>> encoder = get_MLP(dims)\n",
    "    >>> decoder = get_MLP(list(reversed(dims)))\n",
    "    >>> ae_model = nn.Sequential(encoder, decoder)\n",
    "    >>> loss = nn.MSELoss()\n",
    "    >>> optimizer = optim.Adam(ae_model.parameters())\n",
    "    >>> ae = Autoencoder(model=ae_model, loss=loss, optimizer=optimizer)\n",
    "    >>> ae.run_train(100, train_loader)\n",
    "    \"\"\"\n",
    "    def __init__(self, model=None, loss=None,  optimizer=None, device='cuda'):\n",
    "        super(Autoencoder, self).__init__(model, loss, optimizer, device)\n",
    "    \n",
    "    def run_batch(self, i_batch, data):\n",
    "        self.optimizer.zero_grad()\n",
    "        data_in, _ = data\n",
    "        data_in = data_in.to(self.device)\n",
    "        out = self.model(data_in)\n",
    "        loss = self.loss(out, data_in)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.detach().cpu().item()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-range",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "stainless-summary",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/raid/workspace/public/libs/pytorch_examples\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#decoder = get_MLP([100, 300, 784])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#ae_model = nn.Sequential(encoder, decoder)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    848\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    849\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver."
     ]
    }
   ],
   "source": [
    "## TEST\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "    # classifier\n",
    "    dim_mnist = 784\n",
    "                                                  # dim_hiddens ( , activation=nn.ReLU(), dropout=0.1, end=False )\n",
    "    encoder = get_MLP([784, 300, 100, 10]) \n",
    "    #decoder = get_MLP([100, 300, 784])\n",
    "    #ae_model = nn.Sequential(encoder, decoder)\n",
    "    encoder = encoder.to(device)\n",
    "\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(encoder.parameters())\n",
    "    classifier = Net(model=encoder, loss=loss, optimizer=optimizer)\n",
    "    classifier.run_train(20, train_loader)\n",
    "    \n",
    "    # autoencoder\n",
    "    dim_mnist = 784\n",
    "    #dims = [784, 300, 300]\n",
    "    dims = [784, 128, 64, 32]\n",
    "    encoder = get_MLP(dims)\n",
    "    decoder = get_MLP(list(reversed(dims)))\n",
    "    ae_model = nn.Sequential(encoder, decoder)\n",
    "    ae_model = ae_model.to(device)\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(ae_model.parameters())\n",
    "    ae = Autoencoder(model=ae_model, loss=loss, optimizer=optimizer)\n",
    "    ae.run_train(100, train_loader)\n",
    "    \n",
    "    # reconstruction check\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    for i_batch, data_batch in enumerate(test_loader):\n",
    "        if i_batch > 0: \n",
    "            break\n",
    "        with torch.no_grad():\n",
    "            data_in, tgt = data_batch\n",
    "            ii = 50\n",
    "            #data_in0 = data_in[:1]\n",
    "            data_in0 = data_in[ii:ii+1]\n",
    "            data_in0 = data_in0.to(device)\n",
    "            data_in1 = data_in0.cpu().squeeze(0).view(28,28).numpy()\n",
    "            tgt0 = tgt[ii]\n",
    "            out = ae.model(data_in0)\n",
    "            out = out.cpu()\n",
    "            out = out.squeeze(0)\n",
    "            out = out.view(28,28).numpy()\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(data_in1, cmap='gray')\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(out, cmap='gray')\n",
    "            print(tgt0.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-induction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python My Env",
   "language": "python",
   "name": "python-my-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
