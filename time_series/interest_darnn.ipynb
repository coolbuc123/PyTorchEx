{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borrowed some encoder-decoder of dual attention rnn from https://chandlerzuo.github.io/blog/2017/11/darnn\n",
    "\n",
    "These are seq2seq model which predicts final status sequentially.  \n",
    "This is not good because we get errors from each prediction step.  \n",
    "\n",
    "Another thing to note is  \n",
    "In case prediction_period is larger than 1,\n",
    "we do not need to infer all information.  \n",
    "We have information before predicting dates.  \n",
    "So y market data before predicting date can be used in inference.  \n",
    "\n",
    "Results are bad for distant prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame, Series\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "try:\n",
    "    lib_s = '/home/adminuser/public/libs/pytorch_examples/basic_networks'\n",
    "    sys.path.append(lib_s)\n",
    "    import generate_model as nets\n",
    "except:\n",
    "    lib_s = '/home/bwlee/work/codes/examples/basic_networks'\n",
    "    sys.path.append(lib_s)\n",
    "    import generate_model as nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make input data\n",
    "interest.csv has only closed price.   \n",
    "On the other hand, zipline needs OLHCV(?) format for each index  \n",
    "make dummy columns and put 'close' value to them  \n",
    "make csv file for each index  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_s0 = 'interest.csv'\n",
    "df0 = pd.read_csv(f_s0, index_col='date')\n",
    "df0 = df0.iloc[::-1] # 과거에서 현재로 정렬순서 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data without time confusion\n",
    "Seperate two actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized input, norm val, tgt_date, tgt_val, tgt_diff_ratio, \n",
    "class Environ():\n",
    "    def __init__(self):\n",
    "        self.indices = ['trea3', 'trea5', 'trea10']\n",
    "        #self.tgt_index = 'trea10'\n",
    "        self.tgt_index = 'trea3'\n",
    "        # input window size\n",
    "        self.input_size = 30\n",
    "        # prediction is made after algo.pred_period from the present\n",
    "        self.pred_period = 2\n",
    "\n",
    "env = Environ() # setting values\n",
    "mkt_data = {} # object to store data for learning\n",
    "    \n",
    "def push_data(env, data, mkt_data):\n",
    "    \"\"\"\n",
    "    read past data and push them to mkt_data\n",
    "    :param data: dataframe info from csv file\n",
    "    :param mkt_data: dataframe to be used for learning\n",
    "    \"\"\"\n",
    "    for ii_days in range(len(data)):\n",
    "        if ii_days+1 < env.input_size:\n",
    "            continue\n",
    "        elif ii_days+1 == env.input_size:\n",
    "            env.start_date = data.iloc[ii_days].name\n",
    "        \n",
    "        predicting_date = data.iloc[ii_days].name\n",
    "        # historical data from today to env.input_size behind days\n",
    "        history = data.iloc[ii_days+1-env.input_size:ii_days+1]\n",
    "        mean_val = history.mean() \n",
    "        max_val = history.max()\n",
    "        min_val = history.min()\n",
    "        \n",
    "        range_val = max_val - min_val\n",
    "        norm_history = (history-mean_val)/range_val\n",
    "        mkt_data[predicting_date] = [norm_history, mean_val, range_val, \n",
    "                                     None, None, None, None, None]\n",
    "        \n",
    "            \n",
    "def push_tgt(env, data, mkt_data):\n",
    "    \"\"\"\n",
    "    read future data and push them to mkt_data\n",
    "    future_prediction_date is a future date when model want to predict\n",
    "    past_predicting_date is a past date when model made a prediction with given information\n",
    "    :param data: dataframe info from csv file\n",
    "    :param mkt_data: dataframe to be used for learning\n",
    "    \"\"\"\n",
    "    for ii_days in range(len(data)):\n",
    "        ii_predicting = ii_days - env.pred_period\n",
    "        predicting_date = data.iloc[ii_predicting].name\n",
    "        if ii_predicting < 0 or predicting_date < env.start_date:\n",
    "            continue\n",
    "        \n",
    "        past_history = mkt_data[predicting_date][0]\n",
    "        mean_val = mkt_data[predicting_date][1]\n",
    "        range_val = mkt_data[predicting_date][2]\n",
    "        \n",
    "        past_price = (past_history.iloc[-1]*range_val+mean_val)[env.tgt_index] # 49.6\n",
    "        # wrong\n",
    "        #past_priceb = (past_history.iloc[-env.pred_period:]*range_val+mean_val)[env.tgt_index] \n",
    "        #print('past_priceb', past_priceb)\n",
    "        #past_price = (past_history.iloc[-5]*range_val+mean_val)[env.tgt_index] # 56.3\n",
    "        \n",
    "        #mkt_data[predicting_date][0] = past_history[:-4]\n",
    "        \n",
    "        #past_price = (past_history.iloc[-3]*range_val+mean_val)[env.tgt_index] # 53.0, # 53.0\n",
    "        #past_price = (past_history.iloc[-13]*range_val+mean_val)[env.tgt_index] # 67.4\n",
    "        #past_price = (past_history*range_val+mean_val).mean()[env.tgt_index] # 58.4\n",
    "        #past_price = (past_history*range_val+mean_val)[:-3].mean()[env.tgt_index] # 63.2\n",
    "        #past_price = (past_history*range_val+mean_val)[:-5].mean()[env.tgt_index] # 63.7\n",
    "        \n",
    "        #past_price = (past_history.iloc[-10]*range_val+mean_val)[env.tgt_index] # 66.4\n",
    "\n",
    "        #past_price = (past_history.iloc[-5:].mean()*range_val+mean_val)[env.tgt_index] # 48.1\n",
    "        #past_price = (past_history.iloc[-3:].mean()*range_val+mean_val)[env.tgt_index] # 48.1\n",
    "        \n",
    "        #past_price = (past_history.iloc[-10:].mean()*range_val+mean_val)[env.tgt_index] # 55.9\n",
    "        #past_price = (past_history.iloc[-10:-5].mean()*range_val+mean_val)[env.tgt_index] # 60.4\n",
    "        \n",
    "        prediction_date = data.iloc[ii_days].name\n",
    "        #tgt_price = data.iloc[ii_days][env.tgt_index]\n",
    "        # tgt should have one more time step than input, because is has initial value\n",
    "        tgt_price = data.iloc[ii_days-env.input_size:ii_days+1][env.tgt_index]\n",
    "        tgt_price = np.single(tgt_price)\n",
    "        \n",
    "        #tgt_price = (data.iloc[ii_days-1:ii_days+2].mean())[env.tgt_index]\n",
    "        \n",
    "        # ignore dates and subtract to get target history\n",
    "        #tgt_ratio = (tgt_price - np.single(past_price))/np.single(past_price)*10\n",
    "        tgt_ratio = tgt_price/np.single(past_price)\n",
    "        #print('diff', tgt_price - np.single(past_priceb))\n",
    "        #print('ratio', tgt_ratio)\n",
    "        mkt_data[predicting_date][3] = prediction_date\n",
    "        mkt_data[predicting_date][4] = tgt_price\n",
    "        mkt_data[predicting_date][5] = tgt_ratio\n",
    "        \n",
    "        mkt_data[predicting_date][6] = np.single(past_price)\n",
    "        mkt_data[predicting_date][7] = predicting_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Push past data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "push_data(env, df0, mkt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check data are pushed correctly\n",
    "* no dates should be ahead of key date\n",
    "* prediction info are not pushed yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2000-11-11', '2000-11-13', '2000-11-14']\n"
     ]
    }
   ],
   "source": [
    "print(list(mkt_data.keys())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.3000,  0.2721,  0.2940],\n",
       "         [ 0.1060,  0.1314,  0.1522],\n",
       "         [ 0.1060,  0.1314,  0.1522],\n",
       "         [ 0.0910,  0.1240,  0.1522],\n",
       "         [ 0.1507,  0.1758,  0.1837],\n",
       "         [ 0.1060,  0.1240,  0.1365],\n",
       "         [ 0.1284,  0.1240,  0.1050],\n",
       "         [ 0.1582,  0.1610,  0.1365],\n",
       "         [ 0.1582,  0.1610,  0.1365],\n",
       "         [ 0.1881,  0.1980,  0.1759],\n",
       "         [ 0.1881,  0.2054,  0.1759],\n",
       "         [ 0.0761,  0.0721,  0.0499],\n",
       "         [-0.3567, -0.4242, -0.4383],\n",
       "         [-0.7000, -0.7279, -0.7060],\n",
       "         [-0.7000, -0.7279, -0.7060]]),\n",
       " tensor([7.6640, 7.8663, 8.1433]),\n",
       " tensor([0.6700, 0.6750, 0.6350]),\n",
       " '2000-11-29',\n",
       " tensor([7.1350, 7.1550, 7.2450, 7.2900, 7.2750, 7.2750, 7.2950, 7.4200, 7.3550,\n",
       "         7.3850, 7.3500, 7.3500, 7.2750, 7.2350, 7.2400]),\n",
       " tensor([-0.0834, -0.0556,  0.0695,  0.1320,  0.1112,  0.1112,  0.1390,  0.3127,\n",
       "          0.2224,  0.2641,  0.2154,  0.2154,  0.1112,  0.0556,  0.0625]),\n",
       " 7.195,\n",
       " '2000-11-11',\n",
       " tensor([-0.8881, -0.9333, -0.8819, -0.8582, -0.8889, -0.8425, -0.8060, -0.8519,\n",
       "         -0.8425, -0.3433, -0.3037, -0.2677, -0.5149, -0.5852, -0.5748, -0.4627,\n",
       "         -0.5481, -0.5748,  0.0299,  0.0444,  0.0394,  0.0821,  0.0815,  0.0394])]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mkt_data['2000-11-11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2000-11-06'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.start_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Push future data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "push_tgt(env, df0, mkt_data)\n",
    "mkt_data = {key: val for key, val in mkt_data.items() if (val[-1] is not None)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CHECK tgt push is correctly made\n",
    "end value of '2000-11-23' * norm == prediction value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[               trea3     trea5    trea10\n",
      "date                                    \n",
      "2000-10-26  0.300000  0.272099  0.293963\n",
      "2000-10-27  0.105970  0.131358  0.152231\n",
      "2000-10-28  0.105970  0.131358  0.152231\n",
      "2000-10-30  0.091045  0.123951  0.152231\n",
      "2000-10-31  0.150746  0.175802  0.183727\n",
      "2000-11-01  0.105970  0.123951  0.136483\n",
      "2000-11-02  0.128358  0.123951  0.104987\n",
      "2000-11-03  0.158209  0.160988  0.136483\n",
      "2000-11-04  0.158209  0.160988  0.136483\n",
      "2000-11-06  0.188060  0.198025  0.175853\n",
      "2000-11-07  0.188060  0.205432  0.175853\n",
      "2000-11-08  0.076119  0.072099  0.049869\n",
      "2000-11-09 -0.356716 -0.424198 -0.438320\n",
      "2000-11-10 -0.700000 -0.727901 -0.706037\n",
      "2000-11-11 -0.700000 -0.727901 -0.706037, trea3     7.664000\n",
      "trea5     7.866333\n",
      "trea10    8.143333\n",
      "dtype: float64, trea3     0.670\n",
      "trea5     0.675\n",
      "trea10    0.635\n",
      "dtype: float64, '2000-12-05', 7.07, -1.0108074]\n",
      "[               trea3     trea5    trea10\n",
      "date                                    \n",
      "2000-11-07  0.681934  0.687143  0.711795\n",
      "2000-11-08  0.567430  0.558571  0.588718\n",
      "2000-11-09  0.124682  0.080000  0.111795\n",
      "2000-11-10 -0.226463 -0.212857 -0.149744\n",
      "2000-11-11 -0.226463 -0.212857 -0.149744\n",
      "2000-11-13 -0.318066 -0.305714 -0.288205\n",
      "2000-11-14 -0.287532 -0.312857 -0.288205\n",
      "2000-11-15 -0.150127 -0.191429 -0.172821\n",
      "2000-11-16 -0.081425 -0.120000 -0.134359\n",
      "2000-11-17 -0.104326 -0.141429 -0.157436\n",
      "2000-11-18 -0.104326 -0.141429 -0.157436\n",
      "2000-11-20 -0.073791 -0.070000 -0.095897\n",
      "2000-11-21  0.117048  0.151429  0.104103\n",
      "2000-11-22  0.017812  0.072857  0.011795\n",
      "2000-11-23  0.063613  0.158571  0.065641, trea3     7.343333\n",
      "trea5     7.524000\n",
      "trea10    7.792333\n",
      "dtype: float64, trea3     0.655\n",
      "trea5     0.700\n",
      "trea10    0.650\n",
      "dtype: float64, '2000-12-16', 7.11, -0.9541985]\n"
     ]
    }
   ],
   "source": [
    "print(mkt_data['2000-11-11'])\n",
    "print(mkt_data['2000-11-23'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index_data(Dataset):\n",
    "    def __init__(self, in_data, dates):\n",
    "        \"\"\"\n",
    "        :param in_data: dict of (df_past_normed, norm_val, prediction_date, tgt_price, tgt_ratio)\n",
    "        \"\"\"\n",
    "        # change dataframe to float numpy array\n",
    "        for key, val in in_data.items():\n",
    "            if not 'Tensor' in str(type(in_data[key][0])) :\n",
    "                in_data[key][0] = torch.tensor(in_data[key][0].to_numpy(np.single))\n",
    "                in_data[key][1] = torch.tensor(in_data[key][1].to_numpy(np.single))\n",
    "                in_data[key][2] = torch.tensor(in_data[key][2].to_numpy(np.single))\n",
    "                in_data[key][4] = torch.tensor(in_data[key][4])\n",
    "                in_data[key][5] = torch.tensor(in_data[key][5])\n",
    "                \n",
    "                ## add difference\n",
    "                diff = in_data[key][0][-1] - in_data[key][0][-5]\n",
    "                diff2 = in_data[key][0][-1] - in_data[key][0][-7]\n",
    "                diff3 = in_data[key][0][-1] - in_data[key][0][-10]\n",
    "                diff4 = in_data[key][0][-1] - in_data[key][0][-3]\n",
    "                diff5 = in_data[key][0][-3] - in_data[key][0][-7]\n",
    "                diff6 = in_data[key][0][-3] - in_data[key][0][-10]\n",
    "                diff7 = in_data[key][0][-5] - in_data[key][0][-7]\n",
    "                diff8 = in_data[key][0][-5] - in_data[key][0][-10]\n",
    "                #diff = torch.cat((diff, diff2, diff3), dim=-1)\n",
    "                diff = torch.cat((diff, diff2, diff3, diff4, diff5, diff6, diff7, diff8), dim=-1)\n",
    "                in_data[key].append(diff)\n",
    "        self.in_data = in_data\n",
    "        self.i2dates = {}\n",
    "        for ii, date1 in enumerate(dates):\n",
    "             self.i2dates[ii] = date1\n",
    "        \n",
    "    def __getitem__(self, ii_date):\n",
    "        \"\"\"\n",
    "        :return: (df_past_normed, norm_val, prediction_date, tgt_price, tgt_ratio)\n",
    "        \"\"\"\n",
    "        predicting_date = self.i2dates[ii_date]\n",
    "        return self.in_data[predicting_date]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erase data that do not have prediction target\n",
    "traintest_dates = sorted(list(mkt_data.keys()))\n",
    "n_train = len(traintest_dates)*8//10\n",
    "n_test = len(traintest_dates) - n_train\n",
    "train_dates = traintest_dates[:n_train]\n",
    "test_dates = traintest_dates[n_train:]\n",
    "\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "for key, val in mkt_data.items():\n",
    "    if key in train_dates:\n",
    "        train_data[key] = val\n",
    "    elif key in test_dates:\n",
    "        test_data[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dset = Index_data(train_data, train_dates)\n",
    "test_dset = Index_data(test_data, test_dates)\n",
    "train_loader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1070\n"
     ]
    }
   ],
   "source": [
    "print(len(test_dset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.3948, -0.4402, -0.4924],\n",
       "         [-0.4127, -0.4342, -0.4758],\n",
       "         [-0.4307, -0.4704, -0.5015],\n",
       "         [-0.5139, -0.5590, -0.6024],\n",
       "         [-0.3228, -0.2934, -0.2630],\n",
       "         [-0.2105, -0.1324, -0.0520],\n",
       "         [ 0.1041,  0.1996,  0.2508],\n",
       "         [ 0.0592,  0.1091,  0.1407],\n",
       "         [ 0.2951,  0.3022,  0.3058],\n",
       "         [ 0.1491,  0.1392,  0.1315],\n",
       "         [ 0.2884,  0.2720,  0.2893],\n",
       "         [ 0.2727,  0.2700,  0.2783],\n",
       "         [ 0.3064,  0.3062,  0.3150],\n",
       "         [ 0.3243,  0.2901,  0.2783],\n",
       "         [ 0.4861,  0.4410,  0.3976]]),\n",
       " tensor([1.6137, 1.7458, 1.9783]),\n",
       " tensor([0.4450, 0.4970, 0.5450]),\n",
       " '2016-12-15',\n",
       " tensor([1.8300, 1.8230, 1.7480, 1.7100, 1.7220, 1.7250, 1.7600, 1.7200, 1.7370,\n",
       "         1.7310, 1.7090, 1.7350, 1.7160, 1.6620, 1.6450, 1.6950]),\n",
       " tensor([ 0.0000, -0.0383, -0.4481, -0.6557, -0.5902, -0.5738, -0.3825, -0.6011,\n",
       "         -0.5082, -0.5410, -0.6612, -0.5191, -0.6230, -0.9180, -1.0109, -0.7377]),\n",
       " 1.83,\n",
       " '2016-11-24',\n",
       " tensor([ 0.1978,  0.1690,  0.1083,  0.1910,  0.1388,  0.0917,  0.6966,  0.5734,\n",
       "          0.4495,  0.1798,  0.1348,  0.0826,  0.0112,  0.0040,  0.0092,  0.5169,\n",
       "          0.4386,  0.3670, -0.0067, -0.0302, -0.0165,  0.4989,  0.4044,  0.3413])]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "class encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, T):\n",
    "        # input size: number of underlying factors (81)\n",
    "        # T: number of time steps (10)\n",
    "        # hidden_size: dimension of the hidden state\n",
    "        super(encoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.T = T\n",
    "\n",
    "        self.lstm_layer = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = 1)\n",
    "        self.attn_linear = nn.Linear(in_features = 2 * hidden_size + T - 1, out_features = 1)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # input_data: batch_size * T - 1 * input_size        \n",
    "        input_weighted = Variable(input_data.data.new(input_data.size(0), self.T - 1, self.input_size).zero_())\n",
    "        input_encoded = Variable(input_data.data.new(input_data.size(0), self.T - 1, self.hidden_size).zero_())\n",
    "        # hidden, cell: initial states with dimention hidden_size\n",
    "        hidden = self.init_hidden(input_data) # 1 * batch_size * hidden_size\n",
    "        cell = self.init_hidden(input_data)\n",
    "        # hidden.requires_grad = False\n",
    "        # cell.requires_grad = False\n",
    "        for t in range(self.T - 1):\n",
    "            # Eqn. 8: concatenate the hidden states with each predictor\n",
    "            x = torch.cat((hidden.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n",
    "                           cell.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n",
    "                           input_data.permute(0, 2, 1)), dim = 2) # batch_size * input_size * (2*hidden_size + T - 1)\n",
    "            # Eqn. 9: Get attention weights\n",
    "            #print('size', self.hidden_size, self.T, input_data.size())\n",
    "            x = self.attn_linear(x.view(-1, self.hidden_size * 2 + self.T - 1)) # (batch_size * input_size) * 1\n",
    "            attn_weights = F.softmax(x.view(-1, self.input_size)) # batch_size * input_size, attn weights with values sum up to 1.\n",
    "            # Eqn. 10: LSTM\n",
    "            weighted_input = torch.mul(attn_weights, input_data[:, t, :]) # batch_size * input_size\n",
    "            # Fix the warning about non-contiguous memory\n",
    "            # see https://discuss.pytorch.org/t/dataparallel-issue-with-flatten-parameter/8282\n",
    "            self.lstm_layer.flatten_parameters()\n",
    "            _, lstm_states = self.lstm_layer(weighted_input.unsqueeze(0), (hidden, cell))\n",
    "            hidden = lstm_states[0]\n",
    "            cell = lstm_states[1]\n",
    "            # Save output\n",
    "            input_weighted[:, t, :] = weighted_input\n",
    "            input_encoded[:, t, :] = hidden\n",
    "        return input_weighted, input_encoded\n",
    "\n",
    "    def init_hidden(self, x):\n",
    "        # No matter whether CUDA is used, the returned variable will have the same type as x.\n",
    "        return Variable(x.data.new(1, x.size(0), self.hidden_size).zero_()) # dimension 0 is the batch dimension\n",
    "\n",
    "class decoder(nn.Module):\n",
    "    def __init__(self, encoder_hidden_size, decoder_hidden_size, T):\n",
    "        super(decoder, self).__init__()\n",
    "\n",
    "        self.T = T\n",
    "        self.encoder_hidden_size = encoder_hidden_size\n",
    "        self.decoder_hidden_size = decoder_hidden_size\n",
    "\n",
    "        self.attn_layer = nn.Sequential(nn.Linear(2 * decoder_hidden_size + encoder_hidden_size, encoder_hidden_size),\n",
    "                                         nn.Tanh(), nn.Linear(encoder_hidden_size, 1))\n",
    "        self.lstm_layer = nn.LSTM(input_size = 1, hidden_size = decoder_hidden_size)\n",
    "        self.fc = nn.Linear(encoder_hidden_size + 1, 1)\n",
    "        self.fc_final = nn.Linear(decoder_hidden_size + encoder_hidden_size, 1)\n",
    "\n",
    "        self.fc.weight.data.normal_()\n",
    "\n",
    "    def forward(self, input_encoded, y_history):\n",
    "        # input_encoded: batch_size * T - 1 * encoder_hidden_size\n",
    "        # y_history: batch_size * (T-1)\n",
    "        # Initialize hidden and cell, 1 * batch_size * decoder_hidden_size\n",
    "        hidden = self.init_hidden(input_encoded)\n",
    "        cell = self.init_hidden(input_encoded)\n",
    "        # hidden.requires_grad = False\n",
    "        # cell.requires_grad = False\n",
    "        for t in range(self.T - 1):\n",
    "            # Eqn. 12-13: compute attention weights\n",
    "            ## batch_size * T * (2*decoder_hidden_size + encoder_hidden_size)\n",
    "            x = torch.cat((hidden.repeat(self.T - 1, 1, 1).permute(1, 0, 2),\n",
    "                           cell.repeat(self.T - 1, 1, 1).permute(1, 0, 2), input_encoded), dim = 2)\n",
    "            x = F.softmax(self.attn_layer(x.view(-1, 2 * self.decoder_hidden_size + self.encoder_hidden_size\n",
    "                                                )).view(-1, self.T - 1)) # batch_size * T - 1, row sum up to 1\n",
    "            # Eqn. 14: compute context vector\n",
    "            context = torch.bmm(x.unsqueeze(1), input_encoded)[:, 0, :] # batch_size * encoder_hidden_size\n",
    "            if t < self.T - 1:\n",
    "                # Eqn. 15\n",
    "                y_tilde = self.fc(torch.cat((context, y_history[:, t].unsqueeze(1)), dim = 1)) # batch_size * 1\n",
    "                # Eqn. 16: LSTM\n",
    "                self.lstm_layer.flatten_parameters()\n",
    "                _, lstm_output = self.lstm_layer(y_tilde.unsqueeze(0), (hidden, cell))\n",
    "                hidden = lstm_output[0] # 1 * batch_size * decoder_hidden_size\n",
    "                cell = lstm_output[1] # 1 * batch_size * decoder_hidden_size\n",
    "        # Eqn. 22: final output\n",
    "        y_pred = self.fc_final(torch.cat((hidden[0], context), dim = 1))\n",
    "        return y_pred\n",
    "        \n",
    "    def predict(self, input_encoded, y_history):\n",
    "        # input_encoded: batch_size * T - 1 * encoder_hidden_size\n",
    "        # y_history: batch_size * (T-1)\n",
    "        # this is used in cases i-(input-1)+1 <= i-env.period\n",
    "        # Initialize hidden and cell, 1 * batch_size * decoder_hidden_size\n",
    "        with torch.no_grad():\n",
    "            hidden = self.init_hidden(input_encoded)\n",
    "            cell = self.init_hidden(input_encoded)\n",
    "            # y_online : replace history, we do not past values when online predicting\n",
    "            # : batch_size * (T-1)\n",
    "            y_online = torch.zeros(hidden.size()[1], self.T-1).to(device)\n",
    "            #print('y_online', y_online.size())\n",
    "            for t in range(self.T - 1):\n",
    "                # Eqn. 12-13: compute attention weights\n",
    "                ## batch_size * T * (2*decoder_hidden_size + encoder_hidden_size)\n",
    "                x = torch.cat((hidden.repeat(self.T - 1, 1, 1).permute(1, 0, 2),\n",
    "                               cell.repeat(self.T - 1, 1, 1).permute(1, 0, 2), input_encoded), dim = 2)\n",
    "                x = F.softmax(self.attn_layer(x.view(-1, 2 * self.decoder_hidden_size + self.encoder_hidden_size\n",
    "                                                    )).view(-1, self.T - 1)) # batch_size * T - 1, row sum up to 1\n",
    "                # Eqn. 14: compute context vector\n",
    "                context = torch.bmm(x.unsqueeze(1), input_encoded)[:, 0, :] # batch_size * encoder_hidden_size                \n",
    "                if t < self.T - 1:\n",
    "                    # Eqn. 15\n",
    "                    #print('size', 'context', context.size(), 'online', \n",
    "                    #      y_online[:, t].unsqueeze(1).size())\n",
    "                    y_tilde = self.fc(torch.cat((context, y_online[:, t].unsqueeze(1)), dim = 1)) # batch_size * 1\n",
    "                    #print('y_tilde', y_tilde.size())\n",
    "                    # Eqn. 16: LSTM\n",
    "                    self.lstm_layer.flatten_parameters()\n",
    "                    y_output, lstm_output = self.lstm_layer(y_tilde.unsqueeze(0), (hidden, cell))\n",
    "                    hidden = lstm_output[0] # 1 * batch_size * decoder_hidden_size\n",
    "                    cell = lstm_output[1] # 1 * batch_size * decoder_hidden_size\n",
    "\n",
    "                    if t+1 >= self.T-1:\n",
    "                        break\n",
    "                        \n",
    "                    y_pred = self.fc_final(torch.cat((hidden[0], context), dim = 1))\n",
    "                    #print('y_pred', y_pred.size(), 'y_tiled', y_tilde.size())\n",
    "                    # in case, seq2seq out is already known, we can use them\n",
    "                    if env.input_size>= env.pred_period+2:\n",
    "                        if t+1<env.input_size-env.pred_period-1: \n",
    "                            y_online[:, t+1] = y_history[:, t+1].squeeze()\n",
    "                        else:\n",
    "                            y_pred = self.fc_final(torch.cat((hidden[0], context), dim = 1))\n",
    "                            y_online[:, t+1] = y_pred.squeeze()\n",
    "            # Eqn. 22: final output\n",
    "            y_pred = self.fc_final(torch.cat((hidden[0], context), dim = 1))\n",
    "            return y_pred\n",
    "\n",
    "    def init_hidden(self, x):\n",
    "        return Variable(x.data.new(1, x.size(0), self.decoder_hidden_size).zero_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Predictor_rnn(nets.Net):\n",
    "    def __init__(self, downnet=None, dim_hiddens=[200, 200], \n",
    "                 loss=None, optimizer=None, device='cuda:2',\n",
    "                 dim_input=100, bidirectional=True, time_step=15, diff=None):\n",
    "        \"\"\"\n",
    "        net is consists of [embed, rnn, downnet]\n",
    "        :param downnet: define downstream job\n",
    "        \"\"\"\n",
    "        super(Predictor_rnn, self).__init__(loss=loss, device=device)\n",
    "        \n",
    "        encoder_dim_hidden, decoder_dim_hidden = dim_hiddens\n",
    "        self.encoder = encoder(dim_input, encoder_dim_hidden, time_step)\n",
    "        self.decoder = decoder(encoder_dim_hidden, decoder_dim_hidden, time_step)\n",
    "            \n",
    "        if downnet is None:\n",
    "            self.downnet = nets.get_MLP([decoder_dim_hidden, decoder_dim_hidden*2, 1], \n",
    "                                        dropout=0.35, end=True)\n",
    "        else:\n",
    "            self.downnet = downnet\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "        self.encoder = self.encoder.to(device)\n",
    "        self.decoder = self.decoder.to(device)\n",
    "        self.downnet = self.downnet.to(device)\n",
    "        \n",
    "        parms = list(self.encoder.parameters())\n",
    "        parms += list(self.decoder.parameters())\n",
    "        parms += list(self.downnet.parameters())\n",
    "        self.optimizer = optimizer(parms)\n",
    "        \n",
    "        self.diff = diff\n",
    "            \n",
    "        \n",
    "    def set_train(self):\n",
    "        self.encoder.train()\n",
    "        self.decoder.train()\n",
    "        self.downnet.train()\n",
    "        \n",
    "    def set_eval(self):\n",
    "        self.decoder.eval()\n",
    "        self.decoder.eval()\n",
    "        self.downnet.eval()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        # check is there a way to initialize lstm parameters?\n",
    "        for ii, layer in enumerate(self.downnet):\n",
    "            if 'Linear' in str(layer):\n",
    "                #torch.nn.init.xavier_uniform_(self.downnet[ii].weight)\n",
    "                torch.nn.init.xavier_normal_(self.downnet[ii].weight)\n",
    "\n",
    "    def forward(self, x, diff=None, tgt_history=None):\n",
    "        input_weighted, input_encoded = self.encoder(x)\n",
    "        out = self.decoder(input_encoded, tgt_history) \n",
    "        return out.view(-1)\n",
    "    \n",
    "    def predict(self, x, diff=None, tgt_history=None):\n",
    "        input_weighted, input_encoded = self.encoder(x)\n",
    "        out = self.decoder.predict(input_encoded, tgt_history) \n",
    "        return out.view(-1)\n",
    "\n",
    "    def run_eval(self, data):\n",
    "        self.set_eval()\n",
    "        loss = 0\n",
    "        outs = None\n",
    "        tgts = None\n",
    "        with torch.no_grad():\n",
    "            for i_batch, data_batch in enumerate(data):\n",
    "                data_in = data_batch[0][:,1:]\n",
    "                mean_val = data_batch[1]\n",
    "                range_val = data_batch[2]\n",
    "                pred_date = data_batch[3]\n",
    "                tgts_in = data_batch[5]\n",
    "                tgt_history = tgts_in[:,:-1]\n",
    "                tgt = tgts_in[:,-1]\n",
    "                if self.diff is not None:\n",
    "                    diff = data_batch[-1]\n",
    "                    diff = diff.to(self.device)\n",
    "                \n",
    "                data_in = data_in.to(self.device)\n",
    "                tgt = tgt.to(self.device)\n",
    "                tgt_history = tgt_history.to(self.device)\n",
    "                \n",
    "                if self.diff is not None:\n",
    "                    #out = self.forward(data_in, diff, tgt_history)\n",
    "                    out = self.predict(data_in, diff, tgt_history)\n",
    "                else:\n",
    "                    #out = self.forward(data_in, None, tgt_history)\n",
    "                    out = self.predict(data_in, None, tgt_history)\n",
    "                    \n",
    "                #print('loss', loss, self.loss)\n",
    "                loss += self.loss(out, tgt).cpu().numpy()\n",
    "                out = out.cpu().numpy()\n",
    "                #print('loss===', loss)\n",
    "                tgt = tgt.cpu().numpy()\n",
    "                #print('tgt', tgt.shape)\n",
    "                if outs is None:\n",
    "                    outs = out\n",
    "                    tgts = tgt\n",
    "                else:\n",
    "                    outs = np.concatenate((outs, out), axis=0)\n",
    "                    tgts = np.concatenate((tgts, tgt), axis=0)\n",
    "        loss /= 1.0*(i_batch+1)\n",
    "        print('evaluate', 'loss', loss, 'accuracy : define function')\n",
    "        return outs, tgts, loss\n",
    "    \n",
    "    def run_batch(self, i_batch, data_batch):\n",
    "        self.optimizer.zero_grad()\n",
    "        data_in = data_batch[0][:,1:]\n",
    "        mean_val = data_batch[1]\n",
    "        range_val = data_batch[2]\n",
    "        pred_date = data_batch[3]\n",
    "        tgts_in = data_batch[5]\n",
    "        tgt_history = tgts_in[:,:-1]\n",
    "        tgt = tgts_in[:,-1]\n",
    "        if self.diff is not None:\n",
    "            diff = data_batch[-1]\n",
    "            diff = diff.to(self.device)\n",
    "            \n",
    "        data_in = data_in.to(self.device)\n",
    "        tgt = tgt.to(self.device)\n",
    "        tgt_history = tgt_history.to(self.device)\n",
    "        \n",
    "        if self.diff is not None:\n",
    "            out = self.forward(data_in, diff, tgt_history)\n",
    "        else:\n",
    "            out = self.forward(data_in, None, tgt_history)\n",
    "        \n",
    "        loss = self.loss(out, tgt)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.detach().cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_input = train_dset[0][0].shape[-1]\n",
    "time_step = train_dset[0][0].shape[0]\n",
    "dim_hidden = 100\n",
    "#downnet = nets.get_MLP([dim_hidden+3*3, dim_hidden, 1], \n",
    "# Add difference variables\n",
    "downnet = nets.get_MLP([dim_hidden, dim_hidden, 1], \n",
    "#downnet = nets.get_MLP([dim_hidden+3*8, dim_hidden, 1], \n",
    "                        dropout=0.35, end=True)\n",
    "#bidownnet = nets.get_MLP([dim_hidden*2+3*8, dim_hidden*2, 1], \n",
    "#                        dropout=0.0, end=True)\n",
    "loss = nn.MSELoss() # which combines logsoftmax and nll loss\n",
    "optimizer = optim.Adam\n",
    "device = torch.device(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor_rnn(loss=loss, optimizer=optimizer, \n",
    "                          device=device, dim_input=dim_input, \n",
    "                          dim_hiddens=[dim_hidden, dim_hidden], \n",
    "                          downnet=None, bidirectional=False, diff=None, \n",
    "                         time_step=env.input_size)\n",
    "                          #dim_hidden=dim_hidden, downnet=bidownnet, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.12860228629685494\n",
      "eval_train "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate loss 0.0005477339006724086 accuracy : define function\n",
      "epoch 1 loss 0.00038118369628869884\n",
      "eval_train evaluate loss 0.00035803300830702397 accuracy : define function\n",
      "epoch 2 loss 0.00036544392103461356\n",
      "eval_train evaluate loss 0.00035814328206904624 accuracy : define function\n",
      "epoch 3 loss 0.00036232815508091293\n",
      "eval_train evaluate loss 0.000354326714773718 accuracy : define function\n",
      "epoch 4 loss 0.0003606828447403525\n",
      "eval_train evaluate loss 0.00036836467872707366 accuracy : define function\n",
      "epoch 5 loss 0.00036032572032452853\n",
      "eval_train evaluate loss 0.0003542932983637273 accuracy : define function\n",
      "epoch 6 loss 0.000360294001493186\n",
      "eval_train evaluate loss 0.00035258263081082826 accuracy : define function\n",
      "epoch 7 loss 0.0003569716222344467\n",
      "eval_train evaluate loss 0.00037151206686133657 accuracy : define function\n",
      "epoch 8 loss 0.00037142807624733715\n",
      "eval_train evaluate loss 0.00036581343738362193 accuracy : define function\n",
      "epoch 9 loss 0.000362729712140941\n",
      "eval_train evaluate loss 0.0003529496120858882 accuracy : define function\n",
      "epoch 10 loss 0.0003835899851357898\n",
      "eval_train evaluate loss 0.0003836454731089049 accuracy : define function\n",
      "epoch 11 loss 0.0003690060450514751\n",
      "eval_train evaluate loss 0.0003583804413644986 accuracy : define function\n",
      "epoch 12 loss 0.0003662986594856953\n",
      "eval_train evaluate loss 0.0003699495953615449 accuracy : define function\n",
      "epoch 13 loss 0.00037350728734285196\n",
      "eval_train evaluate loss 0.00036368948262386415 accuracy : define function\n",
      "epoch 14 loss 0.0003634662308327075\n",
      "eval_train evaluate loss 0.00036570022652384395 accuracy : define function\n",
      "epoch 15 loss 0.00036686781486287823\n",
      "eval_train evaluate loss 0.0003571722742496753 accuracy : define function\n",
      "epoch 16 loss 0.00036699051530892724\n",
      "eval_train evaluate loss 0.0003538148389927654 accuracy : define function\n",
      "epoch 17 loss 0.00037177340818200707\n",
      "eval_train evaluate loss 0.0003661425716248897 accuracy : define function\n",
      "epoch 18 loss 0.0003630476932079573\n",
      "eval_train evaluate loss 0.0003534698730279038 accuracy : define function\n",
      "epoch 19 loss 0.00036118211378447656\n",
      "eval_train evaluate loss 0.00035268430678007094 accuracy : define function\n",
      "epoch 20 loss 0.0003728259764455342\n",
      "eval_train evaluate loss 0.0003991549888472837 accuracy : define function\n",
      "epoch 21 loss 0.0003688354323159403\n",
      "eval_train evaluate loss 0.00035760786541591663 accuracy : define function\n",
      "epoch 22 loss 0.00036780451838823675\n",
      "eval_train evaluate loss 0.00035710548052439163 accuracy : define function\n",
      "epoch 23 loss 0.0003644949428601635\n",
      "eval_train evaluate loss 0.00037892460896904624 accuracy : define function\n",
      "epoch 24 loss 0.00037785151946434834\n",
      "eval_train evaluate loss 0.0003755669623835763 accuracy : define function\n",
      "epoch 25 loss 0.00037267139731426795\n",
      "eval_train evaluate loss 0.00036013830664268794 accuracy : define function\n",
      "epoch 26 loss 0.00037648952361926045\n",
      "eval_train evaluate loss 0.000390782911476415 accuracy : define function\n",
      "epoch 27 loss 0.00036921310881430757\n",
      "eval_train evaluate loss 0.0003648562034949966 accuracy : define function\n",
      "epoch 28 loss 0.0003734231585942542\n",
      "eval_train evaluate loss 0.0003521014276436711 accuracy : define function\n",
      "epoch 29 loss 0.0003604733403824242\n",
      "eval_train evaluate loss 0.0003688850061300753 accuracy : define function\n"
     ]
    }
   ],
   "source": [
    "predictor.run_train(n_epoch=30, data=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:114: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "rets = {}\n",
    "tgts = None\n",
    "preds = None\n",
    "with torch.no_grad():\n",
    "    for data_batch in test_loader:\n",
    "        data_in = data_batch[0][:,1:]\n",
    "        tgts_in = data_batch[5]\n",
    "        tgt_history = tgts_in[:,:-1]\n",
    "        tgt = tgts_in[:,-1]\n",
    "        #diff = data_batch[-1]\n",
    "        #diff = diff.to(device)\n",
    "        \n",
    "        data_in = data_in.to(device)\n",
    "        tgt_history = tgt_history.to(device)\n",
    "        \n",
    "        tgt = tgt.numpy()\n",
    "        #out = predictor.forward(data_in).cpu().numpy()\n",
    "        out = predictor.predict(data_in, None, tgt_history).cpu().numpy()\n",
    "        if preds is None:\n",
    "            preds = out\n",
    "            tgts = tgt\n",
    "        else:\n",
    "            preds = np.concatenate((preds, out), axis=0)\n",
    "            tgts = np.concatenate((tgts, tgt), axis=0)\n",
    "            \n",
    "        prediction_dates = data_batch[3]\n",
    "        past_prices = data_batch[6]\n",
    "        predicting_dates = data_batch[7]\n",
    "        for ii, date1 in enumerate(prediction_dates):\n",
    "            out1 = out[ii]\n",
    "            #out_orig = out1/10*past_prices[ii] + past_prices[ii]\n",
    "            out_orig = out1*past_prices[ii]\n",
    "            rets[date1] = {'predicting_date': predicting_dates[ii],\n",
    "                          'pred': out_orig,\n",
    "                           'past': past_prices[ii],\n",
    "                           'tgt': data_batch[4][ii][-1]}\n",
    "            \n",
    "preds = preds.reshape(-1)\n",
    "tgts = tgts.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "996"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rets.keys()).index('2021-01-04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 37\n",
      "29 29\n",
      "68 29 0.4264705882352941\n"
     ]
    }
   ],
   "source": [
    "limit = 999\n",
    "sum1 = np.sum((preds[limit:] > 1) & (tgts[limit:] > 1))\n",
    "sum2 = np.sum((preds[limit:] < 1) & (tgts[limit:] < 1))\n",
    "print(sum1, np.sum(tgts[limit:]>1))\n",
    "print(sum2, np.sum(tgts[limit:]<1))\n",
    "print(len(preds[limit:]), sum1+sum2, 1.0*(sum1+sum2)/len(preds[limit:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 492\n",
      "545 545\n",
      "1067 545 0.5107778819119025\n"
     ]
    }
   ],
   "source": [
    "sum1 = np.sum((preds > 1) & (tgts > 1))\n",
    "sum2 = np.sum((preds < 1) & (tgts < 1))\n",
    "print(sum1, np.sum(tgts>1))\n",
    "print(sum2, np.sum(tgts<1))\n",
    "print(len(preds), sum1+sum2, 1.0*(sum1+sum2)/len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets_2021 = {key: val for key, val in rets.items() if key>'2021-01-01'}\n",
    "rows = list(rets_2021['2021-01-04'].keys())\n",
    "cols = list(rets_2021.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets_2021b = {}\n",
    "for col in cols:\n",
    "    for row in rows:\n",
    "        rets_2021b.setdefault(row, {})\n",
    "        val = rets_2021[col][row]\n",
    "        if type(val) is not str:\n",
    "            rets_2021b[row][col] = rets_2021[col][row].item()        \n",
    "        else:\n",
    "            rets_2021b[row][col] = rets_2021[col][row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
