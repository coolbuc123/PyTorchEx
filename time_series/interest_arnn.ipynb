{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply attention.\n",
    "MOdified from dual attention rnn from https://chandlerzuo.github.io/blog/2017/11/darnn\n",
    "\n",
    "These are seq2seq model which predicts final status sequentially.  \n",
    "This is not good because we get errors from each prediction step.  \n",
    "\n",
    "Another thing to note is  \n",
    "In case prediction_period is larger than 1,\n",
    "we do not need to infer all information.  \n",
    "We have information before predicting dates.  \n",
    "So y market data before predicting date can be used in inference.  \n",
    "\n",
    "Results are bad for distant prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame, Series\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "try:\n",
    "    lib_s = '/home/adminuser/public/libs/pytorch_examples/basic_networks'\n",
    "    sys.path.append(lib_s)\n",
    "    import generate_model as nets\n",
    "except:\n",
    "    lib_s = '/home/bwlee/work/codes/examples/basic_networks'\n",
    "    sys.path.append(lib_s)\n",
    "    import generate_model as nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make input data\n",
    "interest.csv has only closed price.   \n",
    "On the other hand, zipline needs OLHCV(?) format for each index  \n",
    "make dummy columns and put 'close' value to them  \n",
    "make csv file for each index  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_s0 = 'interest.csv'\n",
    "df0 = pd.read_csv(f_s0, index_col='date')\n",
    "df0 = df0.iloc[::-1] # 과거에서 현재로 정렬순서 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data without time confusion\n",
    "Seperate two actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized input, norm val, tgt_date, tgt_val, tgt_diff_ratio, \n",
    "class Environ():\n",
    "    def __init__(self):\n",
    "        self.indices = ['trea3', 'trea5', 'trea10']\n",
    "        #self.tgt_index = 'trea10'\n",
    "        self.tgt_index = 'trea3'\n",
    "        # input window size\n",
    "        self.input_size = 30\n",
    "        # prediction is made after algo.pred_period from the present\n",
    "        self.pred_period = 10\n",
    "\n",
    "env = Environ() # setting values\n",
    "mkt_data = {} # object to store data for learning\n",
    "    \n",
    "def push_data(env, data, mkt_data):\n",
    "    \"\"\"\n",
    "    read past data and push them to mkt_data\n",
    "    :param data: dataframe info from csv file\n",
    "    :param mkt_data: dataframe to be used for learning\n",
    "    \"\"\"\n",
    "    for ii_days in range(len(data)):\n",
    "        if ii_days+1 < env.input_size:\n",
    "            continue\n",
    "        elif ii_days+1 == env.input_size:\n",
    "            env.start_date = data.iloc[ii_days].name\n",
    "        \n",
    "        predicting_date = data.iloc[ii_days].name\n",
    "        # historical data from today to env.input_size behind days\n",
    "        history = data.iloc[ii_days+1-env.input_size:ii_days+1]\n",
    "        mean_val = history.mean() \n",
    "        max_val = history.max()\n",
    "        min_val = history.min()\n",
    "        \n",
    "        range_val = max_val - min_val\n",
    "        norm_history = (history-mean_val)/range_val\n",
    "        mkt_data[predicting_date] = [norm_history, mean_val, range_val, \n",
    "                                     None, None, None, None, None]\n",
    "        \n",
    "            \n",
    "def push_tgt(env, data, mkt_data):\n",
    "    \"\"\"\n",
    "    read future data and push them to mkt_data\n",
    "    future_prediction_date is a future date when model want to predict\n",
    "    past_predicting_date is a past date when model made a prediction with given information\n",
    "    :param data: dataframe info from csv file\n",
    "    :param mkt_data: dataframe to be used for learning\n",
    "    \"\"\"\n",
    "    for ii_days in range(len(data)):\n",
    "        ii_predicting = ii_days - env.pred_period\n",
    "        predicting_date = data.iloc[ii_predicting].name\n",
    "        if ii_predicting < 0 or predicting_date < env.start_date:\n",
    "            continue\n",
    "        \n",
    "        past_history = mkt_data[predicting_date][0]\n",
    "        mean_val = mkt_data[predicting_date][1]\n",
    "        range_val = mkt_data[predicting_date][2]\n",
    "        \n",
    "        past_price = (past_history.iloc[-1]*range_val+mean_val)[env.tgt_index] # 49.6\n",
    "        # wrong\n",
    "        #past_priceb = (past_history.iloc[-env.pred_period:]*range_val+mean_val)[env.tgt_index] \n",
    "        #print('past_priceb', past_priceb)\n",
    "        #past_price = (past_history.iloc[-5]*range_val+mean_val)[env.tgt_index] # 56.3\n",
    "        \n",
    "        #mkt_data[predicting_date][0] = past_history[:-4]\n",
    "        \n",
    "        #past_price = (past_history.iloc[-3]*range_val+mean_val)[env.tgt_index] # 53.0, # 53.0\n",
    "        #past_price = (past_history.iloc[-13]*range_val+mean_val)[env.tgt_index] # 67.4\n",
    "        #past_price = (past_history*range_val+mean_val).mean()[env.tgt_index] # 58.4\n",
    "        #past_price = (past_history*range_val+mean_val)[:-3].mean()[env.tgt_index] # 63.2\n",
    "        #past_price = (past_history*range_val+mean_val)[:-5].mean()[env.tgt_index] # 63.7\n",
    "        \n",
    "        #past_price = (past_history.iloc[-10]*range_val+mean_val)[env.tgt_index] # 66.4\n",
    "\n",
    "        #past_price = (past_history.iloc[-5:].mean()*range_val+mean_val)[env.tgt_index] # 48.1\n",
    "        #past_price = (past_history.iloc[-3:].mean()*range_val+mean_val)[env.tgt_index] # 48.1\n",
    "        \n",
    "        #past_price = (past_history.iloc[-10:].mean()*range_val+mean_val)[env.tgt_index] # 55.9\n",
    "        #past_price = (past_history.iloc[-10:-5].mean()*range_val+mean_val)[env.tgt_index] # 60.4\n",
    "        \n",
    "        prediction_date = data.iloc[ii_days].name\n",
    "        tgt_price = data.iloc[ii_days][env.tgt_index]\n",
    "        # tgt should have one more time step than input, because is has initial value\n",
    "        \n",
    "        #tgt_price = (data.iloc[ii_days-1:ii_days+2].mean())[env.tgt_index]\n",
    "        \n",
    "        # ignore dates and subtract to get target history\n",
    "        tgt_ratio = (tgt_price - np.single(past_price))/np.single(past_price)*10\n",
    "        #print('diff', tgt_price - np.single(past_priceb))\n",
    "        #print('ratio', tgt_ratio)\n",
    "        mkt_data[predicting_date][3] = prediction_date\n",
    "        mkt_data[predicting_date][4] = tgt_price\n",
    "        mkt_data[predicting_date][5] = tgt_ratio\n",
    "        \n",
    "        mkt_data[predicting_date][6] = np.single(past_price)\n",
    "        mkt_data[predicting_date][7] = predicting_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Push past data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "push_data(env, df0, mkt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check data are pushed correctly\n",
    "* no dates should be ahead of key date\n",
    "* prediction info are not pushed yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2000-11-11', '2000-11-13', '2000-11-14']\n"
     ]
    }
   ],
   "source": [
    "print(list(mkt_data.keys())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.4524,  0.4331,  0.5433],\n",
       "         [ 0.4401,  0.4331,  0.5433],\n",
       "         [ 0.4278,  0.4089,  0.4139],\n",
       "         [ 0.4278,  0.4271,  0.3891],\n",
       "         [ 0.3910,  0.3725,  0.3493],\n",
       "         [ 0.3481,  0.3362,  0.2647],\n",
       "         [ 0.1885,  0.2210,  0.1751],\n",
       "         [ 0.1885,  0.2210,  0.1751],\n",
       "         [ 0.1763,  0.2149,  0.1751],\n",
       "         [ 0.2254,  0.2574,  0.1950],\n",
       "         [ 0.1885,  0.2149,  0.1652],\n",
       "         [ 0.2070,  0.2149,  0.1453],\n",
       "         [ 0.2315,  0.2453,  0.1652],\n",
       "         [ 0.2315,  0.2453,  0.1652],\n",
       "         [ 0.2560,  0.2756,  0.1900],\n",
       "         [ 0.2560,  0.2816,  0.1900],\n",
       "         [ 0.1640,  0.1725,  0.1104],\n",
       "         [-0.1918, -0.2335, -0.1980],\n",
       "         [-0.4740, -0.4820, -0.3672],\n",
       "         [-0.4740, -0.4820, -0.3672],\n",
       "         [-0.5476, -0.5608, -0.4567],\n",
       "         [-0.5231, -0.5669, -0.4567],\n",
       "         [-0.4127, -0.4638, -0.3821],\n",
       "         [-0.3575, -0.4032, -0.3572],\n",
       "         [-0.3759, -0.4214, -0.3721],\n",
       "         [-0.3759, -0.4214, -0.3721],\n",
       "         [-0.3513, -0.3608, -0.3323],\n",
       "         [-0.1980, -0.1729, -0.2030],\n",
       "         [-0.2777, -0.2396, -0.2627],\n",
       "         [-0.2409, -0.1669, -0.2279]]),\n",
       " tensor([7.5813, 7.7727, 8.0640]),\n",
       " tensor([0.8150, 0.8250, 1.0050]),\n",
       " '2000-12-05',\n",
       " tensor([7.7650, 7.7350, 7.7500, 7.7700, 7.7700, 7.7900, 7.7900, 7.7150, 7.4250,\n",
       "         7.1950, 7.1950, 7.1350, 7.1550, 7.2450, 7.2900, 7.2750, 7.2750, 7.2950,\n",
       "         7.4200, 7.3550, 7.3850, 7.3500, 7.3500, 7.2750, 7.2350, 7.2400, 7.2200,\n",
       "         7.0400, 7.0400, 6.9350, 6.8600]),\n",
       " tensor([1.0515, 1.0474, 1.0494, 1.0521, 1.0521, 1.0548, 1.0548, 1.0447, 1.0054,\n",
       "         0.9743, 0.9743, 0.9661, 0.9689, 0.9810, 0.9871, 0.9851, 0.9851, 0.9878,\n",
       "         1.0047, 0.9959, 1.0000, 0.9953, 0.9953, 0.9851, 0.9797, 0.9804, 0.9777,\n",
       "         0.9533, 0.9533, 0.9391, 0.9289]),\n",
       " 7.385,\n",
       " '2000-11-23',\n",
       " tensor([ 0.1350,  0.2545,  0.1443,  0.1166,  0.2364,  0.1294,  0.3067,  0.3939,\n",
       "          0.2289, -0.0429,  0.0061, -0.0249,  0.1595,  0.2303,  0.1542,  0.3497,\n",
       "          0.3879,  0.2537, -0.0184, -0.0182, -0.0149,  0.1718,  0.1394,  0.0846])]"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mkt_data['2000-11-23']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2000-11-23'"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.start_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Push future data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "push_tgt(env, df0, mkt_data)\n",
    "mkt_data = {key: val for key, val in mkt_data.items() if (val[-1] is not None)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CHECK tgt push is correctly made\n",
    "end value of '2000-11-23' * norm == prediction value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[               trea3     trea5    trea10\n",
      "date                                    \n",
      "2000-10-26  0.300000  0.272099  0.293963\n",
      "2000-10-27  0.105970  0.131358  0.152231\n",
      "2000-10-28  0.105970  0.131358  0.152231\n",
      "2000-10-30  0.091045  0.123951  0.152231\n",
      "2000-10-31  0.150746  0.175802  0.183727\n",
      "2000-11-01  0.105970  0.123951  0.136483\n",
      "2000-11-02  0.128358  0.123951  0.104987\n",
      "2000-11-03  0.158209  0.160988  0.136483\n",
      "2000-11-04  0.158209  0.160988  0.136483\n",
      "2000-11-06  0.188060  0.198025  0.175853\n",
      "2000-11-07  0.188060  0.205432  0.175853\n",
      "2000-11-08  0.076119  0.072099  0.049869\n",
      "2000-11-09 -0.356716 -0.424198 -0.438320\n",
      "2000-11-10 -0.700000 -0.727901 -0.706037\n",
      "2000-11-11 -0.700000 -0.727901 -0.706037, trea3     7.664000\n",
      "trea5     7.866333\n",
      "trea10    8.143333\n",
      "dtype: float64, trea3     0.670\n",
      "trea5     0.675\n",
      "trea10    0.635\n",
      "dtype: float64, '2000-12-05', 7.07, -1.0108074]\n",
      "[               trea3     trea5    trea10\n",
      "date                                    \n",
      "2000-11-07  0.681934  0.687143  0.711795\n",
      "2000-11-08  0.567430  0.558571  0.588718\n",
      "2000-11-09  0.124682  0.080000  0.111795\n",
      "2000-11-10 -0.226463 -0.212857 -0.149744\n",
      "2000-11-11 -0.226463 -0.212857 -0.149744\n",
      "2000-11-13 -0.318066 -0.305714 -0.288205\n",
      "2000-11-14 -0.287532 -0.312857 -0.288205\n",
      "2000-11-15 -0.150127 -0.191429 -0.172821\n",
      "2000-11-16 -0.081425 -0.120000 -0.134359\n",
      "2000-11-17 -0.104326 -0.141429 -0.157436\n",
      "2000-11-18 -0.104326 -0.141429 -0.157436\n",
      "2000-11-20 -0.073791 -0.070000 -0.095897\n",
      "2000-11-21  0.117048  0.151429  0.104103\n",
      "2000-11-22  0.017812  0.072857  0.011795\n",
      "2000-11-23  0.063613  0.158571  0.065641, trea3     7.343333\n",
      "trea5     7.524000\n",
      "trea10    7.792333\n",
      "dtype: float64, trea3     0.655\n",
      "trea5     0.700\n",
      "trea10    0.650\n",
      "dtype: float64, '2000-12-16', 7.11, -0.9541985]\n"
     ]
    }
   ],
   "source": [
    "print(mkt_data['2000-11-11'])\n",
    "print(mkt_data['2000-11-23'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index_data(Dataset):\n",
    "    def __init__(self, in_data, dates):\n",
    "        \"\"\"\n",
    "        :param in_data: dict of (df_past_normed, norm_val, prediction_date, tgt_price, tgt_ratio)\n",
    "        \"\"\"\n",
    "        # change dataframe to float numpy array\n",
    "        for key, val in in_data.items():\n",
    "            if not 'Tensor' in str(type(in_data[key][0])) :\n",
    "                in_data[key][0] = torch.tensor(in_data[key][0].to_numpy(np.single))\n",
    "                in_data[key][1] = torch.tensor(in_data[key][1].to_numpy(np.single))\n",
    "                in_data[key][2] = torch.tensor(in_data[key][2].to_numpy(np.single))\n",
    "                in_data[key][4] = torch.tensor(in_data[key][4])\n",
    "                in_data[key][5] = torch.tensor(in_data[key][5])\n",
    "                \n",
    "                ## add difference\n",
    "                diff = in_data[key][0][-1] - in_data[key][0][-5]\n",
    "                diff2 = in_data[key][0][-1] - in_data[key][0][-7]\n",
    "                diff3 = in_data[key][0][-1] - in_data[key][0][-10]\n",
    "                diff4 = in_data[key][0][-1] - in_data[key][0][-3]\n",
    "                diff5 = in_data[key][0][-3] - in_data[key][0][-7]\n",
    "                diff6 = in_data[key][0][-3] - in_data[key][0][-10]\n",
    "                diff7 = in_data[key][0][-5] - in_data[key][0][-7]\n",
    "                diff8 = in_data[key][0][-5] - in_data[key][0][-10]\n",
    "                #diff = torch.cat((diff, diff2, diff3), dim=-1)\n",
    "                diff = torch.cat((diff, diff2, diff3, diff4, diff5, diff6, diff7, diff8), dim=-1)\n",
    "                in_data[key].append(diff)\n",
    "        self.in_data = in_data\n",
    "        self.i2dates = {}\n",
    "        for ii, date1 in enumerate(dates):\n",
    "             self.i2dates[ii] = date1\n",
    "        \n",
    "    def __getitem__(self, ii_date):\n",
    "        \"\"\"\n",
    "        :return: (df_past_normed, norm_val, prediction_date, tgt_price, tgt_ratio)\n",
    "        \"\"\"\n",
    "        predicting_date = self.i2dates[ii_date]\n",
    "        return self.in_data[predicting_date]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erase data that do not have prediction target\n",
    "traintest_dates = sorted(list(mkt_data.keys()))\n",
    "n_train = len(traintest_dates)*8//10\n",
    "n_test = len(traintest_dates) - n_train\n",
    "train_dates = traintest_dates[:n_train]\n",
    "test_dates = traintest_dates[n_train:]\n",
    "\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "for key, val in mkt_data.items():\n",
    "    if key in train_dates:\n",
    "        train_data[key] = val\n",
    "    elif key in test_dates:\n",
    "        test_data[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dset = Index_data(train_data, train_dates)\n",
    "test_dset = Index_data(test_data, test_dates)\n",
    "train_loader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1070\n"
     ]
    }
   ],
   "source": [
    "print(len(test_dset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.3948, -0.4402, -0.4924],\n",
       "         [-0.4127, -0.4342, -0.4758],\n",
       "         [-0.4307, -0.4704, -0.5015],\n",
       "         [-0.5139, -0.5590, -0.6024],\n",
       "         [-0.3228, -0.2934, -0.2630],\n",
       "         [-0.2105, -0.1324, -0.0520],\n",
       "         [ 0.1041,  0.1996,  0.2508],\n",
       "         [ 0.0592,  0.1091,  0.1407],\n",
       "         [ 0.2951,  0.3022,  0.3058],\n",
       "         [ 0.1491,  0.1392,  0.1315],\n",
       "         [ 0.2884,  0.2720,  0.2893],\n",
       "         [ 0.2727,  0.2700,  0.2783],\n",
       "         [ 0.3064,  0.3062,  0.3150],\n",
       "         [ 0.3243,  0.2901,  0.2783],\n",
       "         [ 0.4861,  0.4410,  0.3976]]),\n",
       " tensor([1.6137, 1.7458, 1.9783]),\n",
       " tensor([0.4450, 0.4970, 0.5450]),\n",
       " '2016-12-15',\n",
       " tensor([1.8300, 1.8230, 1.7480, 1.7100, 1.7220, 1.7250, 1.7600, 1.7200, 1.7370,\n",
       "         1.7310, 1.7090, 1.7350, 1.7160, 1.6620, 1.6450, 1.6950]),\n",
       " tensor([ 0.0000, -0.0383, -0.4481, -0.6557, -0.5902, -0.5738, -0.3825, -0.6011,\n",
       "         -0.5082, -0.5410, -0.6612, -0.5191, -0.6230, -0.9180, -1.0109, -0.7377]),\n",
       " 1.83,\n",
       " '2016-11-24',\n",
       " tensor([ 0.1978,  0.1690,  0.1083,  0.1910,  0.1388,  0.0917,  0.6966,  0.5734,\n",
       "          0.4495,  0.1798,  0.1348,  0.0826,  0.0112,  0.0040,  0.0092,  0.5169,\n",
       "          0.4386,  0.3670, -0.0067, -0.0302, -0.0165,  0.4989,  0.4044,  0.3413])]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "class encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, T):\n",
    "        # input size: number of underlying factors (81)\n",
    "        # T: number of time steps (10)\n",
    "        # hidden_size: dimension of the hidden state\n",
    "        super(encoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.T = T\n",
    "\n",
    "        self.lstm_layer = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = 1)\n",
    "        self.attn_linear = nn.Linear(in_features = 2 * hidden_size + T - 1, out_features = 1)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # input_data: batch_size * T - 1 * input_size        \n",
    "        input_weighted = Variable(input_data.data.new(input_data.size(0), self.T - 1, self.input_size).zero_())\n",
    "        input_encoded = Variable(input_data.data.new(input_data.size(0), self.T - 1, self.hidden_size).zero_())\n",
    "        # hidden, cell: initial states with dimention hidden_size\n",
    "        hidden = self.init_hidden(input_data) # 1 * batch_size * hidden_size\n",
    "        cell = self.init_hidden(input_data)\n",
    "        # hidden.requires_grad = False\n",
    "        # cell.requires_grad = False\n",
    "        for t in range(self.T - 1):\n",
    "            # Eqn. 8: concatenate the hidden states with each predictor\n",
    "            x = torch.cat((hidden.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n",
    "                           cell.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n",
    "                           input_data.permute(0, 2, 1)), dim = 2) # batch_size * input_size * (2*hidden_size + T - 1)\n",
    "            # Eqn. 9: Get attention weights\n",
    "            #print('size', self.hidden_size, self.T, input_data.size())\n",
    "            x = self.attn_linear(x.view(-1, self.hidden_size * 2 + self.T - 1)) # (batch_size * input_size) * 1\n",
    "            attn_weights = F.softmax(x.view(-1, self.input_size)) # batch_size * input_size, attn weights with values sum up to 1.\n",
    "            # Eqn. 10: LSTM\n",
    "            weighted_input = torch.mul(attn_weights, input_data[:, t, :]) # batch_size * input_size\n",
    "            # Fix the warning about non-contiguous memory\n",
    "            # see https://discuss.pytorch.org/t/dataparallel-issue-with-flatten-parameter/8282\n",
    "            self.lstm_layer.flatten_parameters()\n",
    "            output, lstm_states = self.lstm_layer(weighted_input.unsqueeze(0), (hidden, cell))\n",
    "            hidden = lstm_states[0]\n",
    "            cell = lstm_states[1]\n",
    "            # Save output\n",
    "            input_weighted[:, t, :] = weighted_input\n",
    "            input_encoded[:, t, :] = hidden\n",
    "        return input_weighted, input_encoded, output\n",
    "\n",
    "    def init_hidden(self, x):\n",
    "        # No matter whether CUDA is used, the returned variable will have the same type as x.\n",
    "        return Variable(x.data.new(1, x.size(0), self.hidden_size).zero_()) # dimension 0 is the batch dimension\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Predictor_rnn(nets.Net):\n",
    "    def __init__(self, downnet=None, dim_hiddens=[200, 200], \n",
    "                 loss=None, optimizer=None, device='cuda:2',\n",
    "                 dim_input=100, bidirectional=True, time_step=15, diff=None, lr=0.001):\n",
    "        \"\"\"\n",
    "        net is consists of [embed, rnn, downnet]\n",
    "        :param downnet: define downstream job\n",
    "        \"\"\"\n",
    "        super(Predictor_rnn, self).__init__(loss=loss, device=device)\n",
    "        \n",
    "        encoder_dim_hidden, rnn_dim_hidden = dim_hiddens\n",
    "        self.encoder = encoder(dim_input, encoder_dim_hidden, time_step)\n",
    "        self.rnn = nn.LSTM(input_size=dim_input, hidden_size=rnn_dim_hidden,\n",
    "                          num_layers=2, batch_first=True, bidirectional=bidirectional)\n",
    "            \n",
    "        if downnet is None:\n",
    "            self.downnet = nets.get_MLP([rnn_dim_hidden, rnn_dim_hidden*2, 1], \n",
    "                                        dropout=0.35, end=True)\n",
    "        else:\n",
    "            self.downnet = downnet\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "        self.encoder = self.encoder.to(device)\n",
    "        self.rnn = self.rnn.to(device)\n",
    "        self.downnet = self.downnet.to(device)\n",
    "        \n",
    "        parms = list(self.encoder.parameters())\n",
    "        parms += list(self.rnn.parameters())\n",
    "        parms += list(self.downnet.parameters())\n",
    "        self.optimizer = optimizer(parms, lr=lr)\n",
    "        \n",
    "        self.diff = diff\n",
    "            \n",
    "    def set_train(self):\n",
    "        self.encoder.train()\n",
    "        self.rnn.train()\n",
    "        self.downnet.train()\n",
    "        \n",
    "    def set_eval(self):\n",
    "        self.encoder.eval()\n",
    "        self.rnn.eval()\n",
    "        self.downnet.eval()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        # check is there a way to initialize lstm parameters?\n",
    "        for ii, layer in enumerate(self.downnet):\n",
    "            if 'Linear' in str(layer):\n",
    "                #torch.nn.init.xavier_uniform_(self.downnet[ii].weight)\n",
    "                torch.nn.init.xavier_normal_(self.downnet[ii].weight)\n",
    "\n",
    "    def forward(self, x, diff=None):\n",
    "        input_weighted, input_encoded, output = self.encoder(x)\n",
    "        #print('x', x.size())\n",
    "        #print('encoded', input_encoded.size())\n",
    "        \"\"\" test\n",
    "        #out, hidden = self.rnn(x)\n",
    "        out, hidden = self.rnn(input_weighted)\n",
    "        out = out[:,-1] # choose last output\n",
    "        \"\"\"\n",
    "        #\"\"\"\n",
    "        out = output\n",
    "        #\"\"\"\n",
    "        if diff is not None:\n",
    "            #print(out.size())\n",
    "            out = torch.cat((out, diff),dim=1)\n",
    "            #print(diff.size())\n",
    "        out = self.downnet(out)\n",
    "        return out.view(-1)\n",
    "\n",
    "    def run_eval(self, data):\n",
    "        self.set_eval()\n",
    "        loss = 0\n",
    "        outs = None\n",
    "        tgts = None\n",
    "        with torch.no_grad():\n",
    "            for i_batch, data_batch in enumerate(data):\n",
    "                data_in = data_batch[0][:,1:]\n",
    "                mean_val = data_batch[1]\n",
    "                range_val = data_batch[2]\n",
    "                pred_date = data_batch[3]\n",
    "                tgts_in = data_batch[5]\n",
    "                tgt = tgts_in\n",
    "                if self.diff is not None:\n",
    "                    diff = data_batch[-1]\n",
    "                    diff = diff.to(self.device)\n",
    "                \n",
    "                data_in = data_in.to(self.device)\n",
    "                tgt = tgt.to(self.device)\n",
    "                \n",
    "                if self.diff is not None:\n",
    "                    out = self.forward(data_in, diff)\n",
    "                else:\n",
    "                    out = self.forward(data_in, None)\n",
    "                    \n",
    "                #print('loss', loss, self.loss)\n",
    "                loss += self.loss(out, tgt).cpu().numpy()\n",
    "                out = out.cpu().numpy()\n",
    "                #print('loss===', loss)\n",
    "                tgt = tgt.cpu().numpy()\n",
    "                #print('tgt', tgt.shape)\n",
    "                if outs is None:\n",
    "                    outs = out\n",
    "                    tgts = tgt\n",
    "                else:\n",
    "                    outs = np.concatenate((outs, out), axis=0)\n",
    "                    tgts = np.concatenate((tgts, tgt), axis=0)\n",
    "        loss /= 1.0*(i_batch+1)\n",
    "        print('evaluate', 'loss', loss, 'accuracy : define function')\n",
    "        return outs, tgts, loss\n",
    "    \n",
    "    def run_batch(self, i_batch, data_batch):\n",
    "        self.optimizer.zero_grad()\n",
    "        data_in = data_batch[0][:,1:]\n",
    "        mean_val = data_batch[1]\n",
    "        range_val = data_batch[2]\n",
    "        pred_date = data_batch[3]\n",
    "        tgts_in = data_batch[5]\n",
    "        tgt = tgts_in\n",
    "        if self.diff is not None:\n",
    "            diff = data_batch[-1]\n",
    "            diff = diff.to(self.device)\n",
    "            \n",
    "        data_in = data_in.to(self.device)\n",
    "        tgt = tgt.to(self.device)\n",
    "        \n",
    "        if self.diff is not None:\n",
    "            out = self.forward(data_in, diff)\n",
    "        else:\n",
    "            out = self.forward(data_in, None)\n",
    "        \n",
    "        loss = self.loss(out, tgt)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.detach().cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_input = train_dset[0][0].shape[-1]\n",
    "time_step = train_dset[0][0].shape[0]\n",
    "dim_hidden = 20\n",
    "#downnet = nets.get_MLP([dim_hidden+3*3, dim_hidden, 1], \n",
    "# Add difference variables\n",
    "downnet = nets.get_MLP([dim_hidden, dim_hidden, 1], \n",
    "#downnet = nets.get_MLP([dim_hidden+3*8, dim_hidden, 1], \n",
    "                        dropout=0.0, end=True)\n",
    "#bidownnet = nets.get_MLP([dim_hidden*2+3*8, dim_hidden*2, 1], \n",
    "#                        dropout=0.0, end=True)\n",
    "loss = nn.MSELoss() # which combines logsoftmax and nll loss\n",
    "optimizer = optim.Adam\n",
    "device = torch.device(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor_rnn(loss=loss, optimizer=optimizer, \n",
    "                          device=device, dim_input=dim_input, \n",
    "                          dim_hiddens=[dim_hidden, dim_hidden], \n",
    "                          #downnet=None, bidirectional=False, diff=None, \n",
    "                          downnet=downnet, bidirectional=False, diff=True, lr=0.001,\n",
    "                         time_step=env.input_size)\n",
    "                          #dim_hidden=dim_hidden, downnet=bidownnet, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Tensors must have same number of dimensions: got 2 and 3 at /pytorch/aten/src/THC/generic/THCTensorMath.cu:62",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-641-a92dfb3ca4d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/codes/examples/basic_networks/generate_model.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self, n_epoch, data, test_data, eval_step)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mloss_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_temp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-636-c816a26822b0>\u001b[0m in \u001b[0;36mrun_batch\u001b[0;34m(self, i_batch, data_batch)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-636-c816a26822b0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, diff)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m#print(out.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;31m#print(diff.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Tensors must have same number of dimensions: got 2 and 3 at /pytorch/aten/src/THC/generic/THCTensorMath.cu:62"
     ]
    }
   ],
   "source": [
    "predictor.run_train(n_epoch=10, data=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "rets = {}\n",
    "tgts = None\n",
    "preds = None\n",
    "with torch.no_grad():\n",
    "    for data_batch in test_loader:\n",
    "        data_in = data_batch[0][:,1:]\n",
    "        tgts_in = data_batch[5]\n",
    "        tgt = tgts_in\n",
    "        #diff = data_batch[-1]\n",
    "        #diff = diff.to(device)\n",
    "        \n",
    "        data_in = data_in.to(device)\n",
    "        \n",
    "        tgt = tgt.numpy()\n",
    "        out = predictor.forward(data_in, None).cpu().numpy()\n",
    "        if preds is None:\n",
    "            preds = out\n",
    "            tgts = tgt\n",
    "        else:\n",
    "            preds = np.concatenate((preds, out), axis=0)\n",
    "            tgts = np.concatenate((tgts, tgt), axis=0)\n",
    "            \n",
    "        prediction_dates = data_batch[3]\n",
    "        past_prices = data_batch[6]\n",
    "        predicting_dates = data_batch[7]\n",
    "        for ii, date1 in enumerate(prediction_dates):\n",
    "            out1 = out[ii]\n",
    "            #out_orig = out1/10*past_prices[ii] + past_prices[ii]\n",
    "            out_orig = out1*past_prices[ii]\n",
    "            rets[date1] = {'predicting_date': predicting_dates[ii],\n",
    "                          'pred': out_orig,\n",
    "                           'past': past_prices[ii],\n",
    "                           'tgt': data_batch[4][ii]}\n",
    "            \n",
    "preds = preds.reshape(-1)\n",
    "tgts = tgts.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rets.keys()).index('2021-01-04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 48\n",
      "10 19\n",
      "67 28 0.417910447761194\n"
     ]
    }
   ],
   "source": [
    "limit = 999\n",
    "sum1 = np.sum((preds[limit:] > 0) & (tgts[limit:] > 0))\n",
    "sum2 = np.sum((preds[limit:] < 0) & (tgts[limit:] < 0))\n",
    "print(sum1, np.sum(tgts[limit:]>0))\n",
    "print(sum2, np.sum(tgts[limit:]<0))\n",
    "print(len(preds[limit:]), sum1+sum2, 1.0*(sum1+sum2)/len(preds[limit:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 481\n",
      "454 585\n",
      "1066 560 0.525328330206379\n"
     ]
    }
   ],
   "source": [
    "sum1 = np.sum((preds > 0) & (tgts > 0))\n",
    "sum2 = np.sum((preds < 0) & (tgts < 0))\n",
    "print(sum1, np.sum(tgts>0))\n",
    "print(sum2, np.sum(tgts<0))\n",
    "print(len(preds), sum1+sum2, 1.0*(sum1+sum2)/len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets_2021 = {key: val for key, val in rets.items() if key>'2021-01-01'}\n",
    "rows = list(rets_2021['2021-01-04'].keys())\n",
    "cols = list(rets_2021.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets_2021b = {}\n",
    "for col in cols:\n",
    "    for row in rows:\n",
    "        rets_2021b.setdefault(row, {})\n",
    "        val = rets_2021[col][row]\n",
    "        if type(val) is not str:\n",
    "            rets_2021b[row][col] = rets_2021[col][row].item()        \n",
    "        else:\n",
    "            rets_2021b[row][col] = rets_2021[col][row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
