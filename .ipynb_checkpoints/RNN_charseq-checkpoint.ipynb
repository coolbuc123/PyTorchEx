{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sublime-uzbekistan",
   "metadata": {},
   "source": [
    "### RNN - charseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "genuine-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "italic-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_set = ['h','i','e','l','o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "completed-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "seeing-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[0,1,0,2,3,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "permanent-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_one_hot = [[1,0,0,0,0],\n",
    "            [0,1,0,0,0],\n",
    "            [1,0,0,0,0],\n",
    "            [0,0,1,0,0],\n",
    "            [0,0,0,1,0],\n",
    "            [0,0,0,1,0]]\n",
    "y = [[1,0,2,3,3,4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-revision",
   "metadata": {},
   "source": [
    "#### simple하게 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "nutritional-function",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0]]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = [1,0,0,0,0]\n",
    "i  = [0,1,0,0,0] \n",
    "e = [0,0,1,0,0]\n",
    "l  = [0,0,0,1,0]\n",
    "o = [0,0,0,0,1]\n",
    "\n",
    "x_one_hot = [h,i,h,e,l,l]\n",
    "x_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bridal-saver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloTensor(x_one_hot)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "empty-grill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = len(char_set)\n",
    "hidden_size = len(char_set)\n",
    "\n",
    "len(char_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "outside-newsletter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of tensfor :  torch.Size([1, 10, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-4.8442e-31,  4.5637e-41,  0.0000e+00,  0.0000e+00,  1.4013e-45],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00, -4.6946e-36,  3.0781e-41,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.4013e-45,  0.0000e+00,  1.1210e-44,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4013e-45,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 1.1210e-44,  0.0000e+00,  9.1844e-41,  3.5733e-43,  1.4013e-45],\n",
       "         [ 1.4013e-45,  2.8700e-41,  0.0000e+00,  1.4013e-45,  0.0000e+00]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ex = torch.Tensor(1,10,5)\n",
    "print(\"shape of tensfor : \", input_ex.shape)\n",
    "input_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-distance",
   "metadata": {},
   "source": [
    "### Size Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "aggregate-multimedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 5\n",
    "hidden_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "polyphonic-water",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 5])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ex.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-rhythm",
   "metadata": {},
   "source": [
    "### 1 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "informed-employee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.shape:  torch.Size([1, 10, 8])\n",
      "_status.shape:  torch.Size([1, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN( input_size, hidden_size, batch_first=True)  # nn.RNN(5, 8, batch_first=True)\n",
    "output, _status = rnn(input_ex)\n",
    "print(\"output.shape: \", output.shape) # 총 10번의 시점동안 8차원의 hidden state가 출력되었다는 뜻\n",
    "print(\"_status.shape: \", _status.shape) # 마지막 시점의 hidden state 크기 (층의갯수, 배치크기, 은닉상태크기)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-designer",
   "metadata": {},
   "source": [
    "### 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "invisible-detail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.shape:  torch.Size([1, 10, 8])\n",
      "_status.shape:  torch.Size([2, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(input_size, hidden_size, num_layers=2, batch_first=True)   # nn.RNN(5, 8, 2, batch_first=True)\n",
    "output, _status = rnn(input_ex)\n",
    "print(\"output.shape: \", output.shape) # 총 10번의 시점동안 8차원의 hidden state가 출력되었다는 뜻\n",
    "print(\"_status.shape: \", _status.shape) # 마지막 시점의 hidden state 크기 (층의갯수, 배치크기, 은닉상태크기)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-frequency",
   "metadata": {},
   "source": [
    "### bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "seven-orientation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.shape:  torch.Size([1, 10, 16])\n",
      "_status.shape:  torch.Size([4, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(input_size, hidden_size, num_layers=2, bidirectional=True, batch_first=True) # nn.RNN(5, 8, 2, bidirectional=True, batch_first=True) \n",
    "output, _status = rnn(input_ex)\n",
    "print(\"output.shape: \", output.shape) # 총 10번의 시점동안 8차원의 hidden state가 출력되었다는 뜻\n",
    "print(\"_status.shape: \", _status.shape) # 마지막 시점의 hidden state 크기 (층의갯수, 배치크기, 은닉상태크기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "afraid-boxing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "sitting-turkish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1., 0.]]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_view = x.view([1,6,5])\n",
    "x_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "stupid-harrison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 4])\n",
      "torch.Size([1, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 4\n",
    "rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "output, hn = rnn(x_view)\n",
    "print(output.shape)\n",
    "print(hn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ongoing-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(rnn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-picnic",
   "metadata": {},
   "source": [
    "##### temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "remarkable-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "hidden_size = 10\n",
    "rnn = nn.RNN(input_size, hidden_size, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "young-james",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n",
      "torch.Size([1, 5, 20])\n"
     ]
    }
   ],
   "source": [
    "outputs, _status = rnn(input)\n",
    "print(outputs.shape)\n",
    "print(_status.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "lesser-andrew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "formed-supplement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs.shape: torch.Size([5, 3, 20])\n",
      "type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-204-b388cacbc04f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"outputs.shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"type:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"outputs.view(-1, input_size):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     loss = criterion(outputs.view(-1, input_size), Y.view(-1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    outputs, _status = rnn(input)\n",
    "    print(\"outputs.shape:\", outputs.shape)\n",
    "    print(\"type:\", type(outputs))\n",
    "    print(\"outputs.view(-1, input_size):\", outputs.view(-1, input_size))\n",
    "    \n",
    "#     loss = criterion(outputs.view(-1, input_size), Y.view(-1))\n",
    "    \n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     result=outputs.data.numpy().argmax(axis=2)\n",
    "#     result_str = ''.join([char_set[c] for c in np.squeeze(result)])\n",
    "#     print(i, \"loss: \", loss.item(), \"prediction:\", result, \"true Y:\", y_data, \"predctioni str: \", result_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-music",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python My Env",
   "language": "python",
   "name": "python-my-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
